df[
'label'] == 0
] df[processed_
    class_1 = processed_df[processed_df['label'] == 1]
    # Split each class into train and test subsets (stratified split)
    train_0, test_0 = train_test_split(class_0, test_size=0.2, random_state=42)
    train_1, test_1 = train_test_split(class_1, test_size=0.2, random_state=42)
    # Combine and shuffle train/test sets
    train_data = pd.concat([train_0, train_1]).sample(frac=1, random_state=42).reset_index(drop=True) import os
print(os.listdir('/content'))
from google.colab import files
uploaded = files.upload()  # Upload Img.zip
!unzip Img.zip -d /content/
import os
print(os.listdir('/content/Img'))  # Should list .png files
img_dir = '/content/Img'
all_files = [f for f in os.listdir(img_dir) if f.endswith('.png')]
import os
img_dir = '/content/Img' # Changed 'img' to 'Img' to match the unzipped directory
files = os.listdir(img_dir)
print(f"Total images: {len(files)}")
print(files[:10])  # Show first 10 files
import pandas as pd
df = pd.read_csv('/content/english.csv')
print(df['image'].head())
import pandas as pd
import os
import cv2
import numpy as np
# Paths
csv_path = '/content/english.csv'
img_dir = '/content/Img'
# Step 1: Load CSV and available image filenames
df = pd.read_csv(csv_path)
available_images = set(os.listdir(img_dir))
# Step 2: Extract base filenames from CSV and match with available files
df['image_filename'] = df['image'].apply(lambda x: os.path.basename(str(x)).strip())
# Step 3: Keep only rows with matching image files and desired labels
df_filtered = df[df['image_filename'].isin(available_images)]
df_filtered = df_filtered[df_filtered['label'].isin(['N', 'G'])]
print(f"ðŸ§¹ Filtered to {len(df_filtered)} images with labels 'N' or 'G' that actually exist.")
# Step 4: Process images
data = []
for _, row in df_filtered.iterrows():
    image_path = os.path.join(img_dir, row['image_filename'])
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if image is None:
        print(f"âš ï¸ Could not read {image_path}")
        continue
    resized = cv2.resize(image, (28, 28))
    flat = resized.flatten()
    numeric_label = 1 if row['label'] == 'N' else 0
    data.append(np.append(flat, numeric_label))
# Step 5: Create and save DataFrame
if data:
    num_features = len(data[0]) - 1
    col_names = [f'pixel_{i}' for i in range(num_features)] + ['label']
    df_processed = pd.DataFrame(data, columns=col_names)
    df_processed.to_csv('processed_images.csv', index=False)
    print(f"âœ… Saved {len(df_processed)} processed images to 'processed_images.csv'")
else:
    print("âŒ No data was processed. Check image filenames or filtering logic.")
import matplotlib.pyplot as plt

# Load the processed data
df = pd.read_csv('processed_images.csv')
# Plot 6 samples
for i in range(6):
    pixels = df.iloc[i, :-1].values.reshape(28, 28)
    label = df.iloc[i, -1]
    plt.subplot(2, 3, i + 1)
    plt.imshow(pixels, cmap='gray')
    plt.title(f"Label: {'N' if label == 1 else 'G'}")
    plt.axis('off')
plt.tight_layout()
plt.show()
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
# Step 1: Load processed CSV
processed_data = pd.read_csv('processed_images.csv')
# Step 2: Split data into balanced train and test sets
def split_data(processed_df):
    # Separate by label
    class_0 = processed_
    test_data = pd.concat([test_0, test_1]).sample(frac=1, random_state=42).reset_index(drop=True)
    # Split into features and labels
    X_train = train_data.iloc[:, :-1].values
    y_train = train_data.iloc[:, -1].values
    X_test = test_data.iloc[:, :-1].values
    y_test = test_data.iloc[:, -1].values
    return X_train, X_test, y_train, y_test
# Step 3: Initialize weights and hyperparameters
def initialize_parameters(num_features):
    weights = np.random.rand(num_features)  # Initialize random weights
    learning_rate = 0.01  # Learning rate
    num_iterations = 20   # Number of training iterations
    return weights, learning_rate, num_iterations
# Step 4: Call the functions
X_train, X_test, y_train, y_test = split_data(processed_data)
num_features = X_train.shape[1]
weights, learning_rate, num_iterations = initialize_parameters(num_features)
# Display training setup
print(f"âœ… Training samples: {len(X_train)}, Test samples: {len(X_test)}")
print(f"ðŸ“Œ Learning rate: {learning_rate}")
print(f"ðŸ” Number of iterations: {num_iterations}")
import matplotlib.pyplot as plt
# Activation functions
def linear_activation(x):
    return x
def step_activation(x):
    return 1 if x >= 0 else 0
def sigmoid_activation(x):
    return 1 / (1 + np.exp(-x))
# Train the data
def train_model(X_train, y_train, weights, learning_rate, num_iterations, activation_function):
    total_errors = []
    for iteration in range(num_iterations):
        iteration_error = 0
        for i in range(len(X_train)):
            x = X_train[i]
            y = y_train[i]
            # Calculate activation(w.x)
            weighted_sum = np.dot(weights, x)
            prediction = activation_function(weighted_sum)
            # Calculate the error
            error = y - prediction
            iteration_error += error ** 2
            # Update weights
            weights += learning_rate * error * x
        total_errors.append(iteration_error)
# Plot the total errors over iterations
    plt.figure(figsize=(10, 6))
    plt.plot(range(num_iterations), total_errors, label="Total Error")
    plt.xlabel("Iteration")
    plt.ylabel("Total Error")
    plt.title("Error vs. Iterations")
    plt.legend()
    plt.show()
    return weights
# Choose activation function (e.g., linear_activation, step_activation, sigmoid_activation)
activation_function = step_activation
# Train the model
trained_weights = train_model(X_train, y_train, weights, learning_rate, num_iterations, activation_function)
# Display final weights
print(f"Trained weights: {trained_weights}")
# Predict and validate
def predict(X_test, weights, activation_function):
    predictions = []
    for x in X_test:
        weighted_sum = np.dot(weights, x)
        prediction = activation_function(weighted_sum)
        predictions.append(1 if prediction >= 0.5 else 0)  # Threshold for classification
    return predictions
def validate(y_test, predictions):
    correct = np.sum(y_test == predictions)
    accuracy = correct / len(y_test)
    return accuracy
# Predict on test data
predictions = predict(X_test, trained_weights, activation_function)
# Validate accuracy
accuracy = validate(y_test, predictions)
# Display results
# print(f"Trained weights: {trained_weights}")
print(f"Accuracy on test data: {accuracy * 100:.2f}%")
import matplotlib.pyplot as plt
# Display 5 samples of label "G"
def display_label_g_samples(X_test, y_test, predictions):
    samples = []
    # Collect 5 samples for label "G" (0)
    for i in range(len(y_test)):
        if y_test[i] == 0 and len(samples) < 10:
            samples.append((X_test[i], predictions[i]))
        if len(samples) >= 10:
            break
    # Plot the samples
    fig, axes = plt.subplots(1, 10, figsize=(15, 3))
    for idx, (sample, prediction) in enumerate(samples):
        image = sample.reshape(28, 28)
        axes[idx].imshow(image, cmap='gray')
        axes[idx].set_title(f"Pred: {'G' if prediction == 0 else 'N'}")
        axes[idx].axis('off')
        plt.tight_layout()
    plt.show()
# Display 5 samples of label "G"
display_label_g_samples(X_test, y_test, predictions)
# Display 5 samples of label "G"
def display_label_n_samples(X_test, y_test, predictions):
    samples = []
    # Collect 5 samples for label "G" (0)
    for i in range(len(y_test)):
        if y_test[i] == 1 and len(samples) < 10:
            samples.append((X_test[i], predictions[i]))
        if len(samples) >= 10:
            break
    # Plot the samples
    fig, axes = plt.subplots(1, 10, figsize=(15, 3))
    for idx, (sample, prediction) in enumerate(samples):
        image = sample.reshape(28, 28)
        axes[idx].imshow(image, cmap='gray')
        axes[idx].set_title(f"Pred: {'G' if prediction == 0 else 'N'}")
        axes[idx].axis('off')
    plt.tight_layout()
    plt.show()
  # Display 5 samples of label "G"
display_label_n_samples(X_test, y_test, predictions)

